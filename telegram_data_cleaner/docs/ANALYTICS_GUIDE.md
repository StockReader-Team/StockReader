# Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¬Ø§Ù…Ø¹ Ø³ÛŒØ³ØªÙ… Ø¢Ù†Ø§Ù„ÛŒØªÛŒÚ©Ø³

## ğŸ“Š Ù…Ø¹Ø±ÙÛŒ

Ø³ÛŒØ³ØªÙ… Analytics Ø¨Ù‡ Ø´Ù…Ø§ Ø§Ù…Ú©Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ Ø¨Ù‡ Ø·ÙˆØ± Ø¯Ù‚ÛŒÙ‚ Ù…Ø­ØªÙˆØ§ÛŒ Ù‡Ø± Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯ Ùˆ Ø¨ÙÙ‡Ù…ÛŒØ¯ Ú©Ù‡:
- Ú©Ø§Ù†Ø§Ù„ Ú†Ù†Ø¯ Ù¾ÛŒØ§Ù… Ø¯Ø§Ø±Ø¯ØŸ
- Ú†Ù†Ø¯ Ø¯Ø±ØµØ¯ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ ØªØ·Ø§Ø¨Ù‚ Ø¨Ø§ Ù„ØºØªâ€ŒÙ†Ø§Ù…Ù‡ Ø¯Ø§Ø±Ù†Ø¯ØŸ
- Ú©Ø§Ù†Ø§Ù„ Ø±ÙˆÛŒ Ú†Ù‡ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ùˆ ØµÙ†Ø§ÛŒØ¹ÛŒ ØªÙ…Ø±Ú©Ø² Ø¯Ø§Ø±Ø¯ØŸ
- Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ø§Ù†Ø§Ù„ Ø¯Ø± Ø·ÙˆÙ„ Ø²Ù…Ø§Ù† Ú†Ú¯ÙˆÙ†Ù‡ ØªØºÛŒÛŒØ± Ú©Ø±Ø¯Ù‡ØŸ

---

## ğŸ¯ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§

### 1. ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø¨Ø±ÛŒ Ø¨ÙˆØ±Ø³
- Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨ÛŒØ´ØªØ± Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø®Ø§Øµ ØµØ­Ø¨Øª Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
- Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ Ø¯Ø± ÛŒÚ© ØµÙ†Ø¹Øª

### 2. Monitoring ØªØºÛŒÛŒØ±Ø§Øª
- Ø±Ø¯ÛŒØ§Ø¨ÛŒ ØªØºÛŒÛŒØ± ØªÙ…Ø±Ú©Ø² ÛŒÚ© Ú©Ø§Ù†Ø§Ù„ Ø¯Ø± Ø·ÙˆÙ„ Ø²Ù…Ø§Ù†
- Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Trending topics

### 3. Ú¯Ø²Ø§Ø±Ø´â€ŒØ¯Ù‡ÛŒ
- ØªÙ‡ÛŒÙ‡ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª
- Export Ø¨Ù‡ Excel Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±

---

## ğŸ“ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø³ÛŒØ³ØªÙ…

### Flow Ø¯Ø§Ø¯Ù‡

```
1. Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
   â†“
2. Matching: ØªØ·Ø§Ø¨Ù‚ Ø¨Ø§ Ù„ØºØªâ€ŒÙ†Ø§Ù…Ù‡
   â†“
3. Aggregation Job (Ù‡Ø± 5 Ø¯Ù‚ÛŒÙ‚Ù‡):
   - Ø´Ù…Ø§Ø±Ø´ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§
   - Ø´Ù…Ø§Ø±Ø´ ØªØ·Ø§Ø¨Ù‚â€ŒÙ‡Ø§
   - Ù…Ø­Ø§Ø³Ø¨Ù‡ Top 10 Ù†Ù…Ø§Ø¯Ù‡Ø§
   - Ù…Ø­Ø§Ø³Ø¨Ù‡ Top 10 ØµÙ†Ø§ÛŒØ¹
   - Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªÙˆØ²ÛŒØ¹ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§
   â†“
4. Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¬Ø¯ÙˆÙ„ channel_analytics
   â†“
5. Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± UI / API
```

### Ø¬Ø¯ÙˆÙ„ channel_analytics

```sql
CREATE TABLE channel_analytics (
  id UUID PRIMARY KEY,
  channel_id UUID NOT NULL,

  -- Time dimensions
  date DATE NOT NULL,
  hour INTEGER,  -- 0-23 (NULL Ø¨Ø±Ø§ÛŒ daily)
  day_of_week INTEGER,  -- 0-6 (Ø´Ù†Ø¨Ù‡-Ø¬Ù…Ø¹Ù‡)

  -- Metrics
  message_count INTEGER DEFAULT 0,
  match_count INTEGER DEFAULT 0,

  -- Top lists (JSONB)
  top_symbols JSONB,  -- [{"id": "...", "word": "ÙÙˆÙ„Ø§Ø¯", "count": 15}, ...]
  top_industries JSONB,  -- [{"name": "ÙÙ„Ø²Ø§Øª", "count": 25}, ...]
  top_categories JSONB,  -- [{"id": "...", "name": "Ù†Ù…Ø§Ø¯Ù‡Ø§", "count": 50}, ...]

  created_at TIMESTAMP,
  updated_at TIMESTAMP,

  UNIQUE(channel_id, date, hour)
);
```

---

## ğŸ”§ Ù†Ø­ÙˆÙ‡ Ú©Ø§Ø± Ø³ÛŒØ³ØªÙ…

### 1. Aggregation (Ø®ÙˆØ¯Ú©Ø§Ø±)

Ù‡Ø± 5 Ø¯Ù‚ÛŒÙ‚Ù‡ ÛŒÚ©Ø¨Ø§Ø±ØŒ job Ø²ÛŒØ± Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯:

```python
async def _analytics_aggregation_job(self):
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ aggregates Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø¹Øª Ø¬Ø§Ø±ÛŒ
    now = datetime.utcnow()
    start_hour = now.replace(minute=0, second=0, microsecond=0)

    analytics_service = ChannelAnalyticsService(session)

    records_created = await analytics_service.compute_aggregates(
        start_datetime=start_hour,
        end_datetime=now,
        granularity="hourly"
    )
```

### 2. Ù…Ø­Ø§Ø³Ø¨Ù‡ Aggregates

Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ø§Ù†Ø§Ù„ Ùˆ Ù‡Ø± Ø³Ø§Ø¹Øª:

```python
# 1. Ø´Ù…Ø§Ø±Ø´ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ø¯Ø± Ø§ÛŒÙ† Ø³Ø§Ø¹Øª
messages = await session.execute(
    select(Message)
    .where(
        Message.channel_id == channel_id,
        Message.created_at >= start_hour,
        Message.created_at < end_hour
    )
)

# 2. Ø´Ù…Ø§Ø±Ø´ ØªØ·Ø§Ø¨Ù‚â€ŒÙ‡Ø§
match_count = await session.execute(
    select(func.count(distinct(MessageDictionary.message_id)))
    .where(MessageDictionary.message_id.in_(message_ids))
)

# 3. Top 10 Ù†Ù…Ø§Ø¯Ù‡Ø§ (Ø§Ø² Ø¯Ø³ØªÙ‡ "Ù†Ù…Ø§Ø¯Ù‡Ø§")
top_symbols = await session.execute(
    select(
        DictionaryWord.id,
        DictionaryWord.word,
        func.count(MessageDictionary.id).label('count')
    )
    .join(MessageDictionary)
    .where(
        MessageDictionary.message_id.in_(message_ids),
        DictionaryWord.category_id == symbols_category_id
    )
    .group_by(DictionaryWord.id, DictionaryWord.word)
    .order_by(func.count(MessageDictionary.id).desc())
    .limit(10)
)

# 4. Top 10 ØµÙ†Ø§ÛŒØ¹ (Ø§Ø² extra_data)
industries = Counter()
for word in matched_words:
    industry = word.extra_data.get('industry_name')
    if industry:
        industries[industry] += 1

top_industries = industries.most_common(10)

# 5. Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¬Ø¯ÙˆÙ„
analytics_record = ChannelAnalytics(
    channel_id=channel_id,
    date=now.date(),
    hour=now.hour,
    day_of_week=now.weekday(),
    message_count=len(messages),
    match_count=match_count,
    top_symbols=[...],
    top_industries=[...],
    top_categories=[...]
)
```

---

## ğŸŒ API Endpoints

### 1. Ø¢Ù…Ø§Ø± Real-time

```http
GET /api/analytics/channels/{channel_id}/stats?time_range=30min
```

**Ø¨Ø§Ø²Ù‡â€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ**:
- `5min`: 5 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø§Ø®ÛŒØ± (query Ù…Ø³ØªÙ‚ÛŒÙ… Ø§Ø² messages)
- `30min`: 30 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø§Ø®ÛŒØ± (query Ù…Ø³ØªÙ‚ÛŒÙ…)
- `1hour`: 1 Ø³Ø§Ø¹Øª Ø§Ø®ÛŒØ± (query Ù…Ø³ØªÙ‚ÛŒÙ…)
- `today`: Ø§Ù…Ø±ÙˆØ² (Ø§Ø² aggregates)
- `7days`: 7 Ø±ÙˆØ² Ø§Ø®ÛŒØ± (Ø§Ø² aggregates)
- `30days`: 30 Ø±ÙˆØ² Ø§Ø®ÛŒØ± (Ø§Ø² aggregates)

**Ù†Ø­ÙˆÙ‡ Ú©Ø§Ø±**:
- Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ù‡â€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡: query Ù…Ø³ØªÙ‚ÛŒÙ… Ø§Ø² Ø¬Ø¯ÙˆÙ„ `messages`
- Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ù‡â€ŒÙ‡Ø§ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ: Ø®ÙˆØ§Ù†Ø¯Ù† Ø§Ø² `channel_analytics`

```python
if time_range in ["5min", "30min", "1hour"]:
    # Real-time query
    stats = await get_realtime_stats(channel_id, minutes)
else:
    # From aggregates
    stats = await get_channel_content_profile(channel_id, days)
```

### 2. Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ù…Ø­ØªÙˆØ§ÛŒÛŒ

```http
GET /api/analytics/channels/{channel_id}/content-profile?days=7
```

**Ø®Ø±ÙˆØ¬ÛŒ**:
```json
{
  "channel_id": "uuid",
  "days": 7,
  "total_messages": 5000,
  "total_matches": 1500,
  "categories": [
    {"name": "Ù†Ù…Ø§Ø¯Ù‡Ø§", "count": 1200, "percentage": 80.0},
    {"name": "Ø§Ø®Ø¨Ø§Ø±", "count": 300, "percentage": 20.0}
  ],
  "primary_focus": "Ù†Ù…Ø§Ø¯Ù‡Ø§",
  "focus_percentage": 80.0
}
```

### 3. Ù…Ù‚Ø§ÛŒØ³Ù‡ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§

```http
GET /api/analytics/channels/compare?channel_ids=uuid1,uuid2,uuid3&days=7
```

**Ú©Ø§Ø±Ø¨Ø±Ø¯**: Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡Ù…Ø²Ù…Ø§Ù† ØªØ§ 10 Ú©Ø§Ù†Ø§Ù„

### 4. Excel Export

```http
GET /api/analytics/channels/{channel_id}/export/excel?days=7
```

**Ø³Ø§Ø®ØªØ§Ø± Excel**:

#### Sheet 1: Overview
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Analysis Period (days)   â”‚ 7      â”‚
â”‚ Total Messages           â”‚ 5000   â”‚
â”‚ Total Matches            â”‚ 1500   â”‚
â”‚ Primary Focus            â”‚ Ù†Ù…Ø§Ø¯Ù‡Ø§ â”‚
â”‚ Focus Percentage         â”‚ 80%    â”‚
â”‚                          â”‚        â”‚
â”‚ Last Hour Stats          â”‚        â”‚
â”‚ Messages (last hour)     â”‚ 45     â”‚
â”‚ Matches (last hour)      â”‚ 12     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Sheet 2: Categories
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Category  â”‚ Match Count â”‚ Percentage â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Ù†Ù…Ø§Ø¯Ù‡Ø§    â”‚ 1200        â”‚ 80%        â”‚
â”‚ Ø§Ø®Ø¨Ø§Ø±     â”‚ 300         â”‚ 20%        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Sheet 3: Top Symbols
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Symbol  â”‚ Match Count â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ÙÙˆÙ„Ø§Ø¯   â”‚ 150         â”‚
â”‚ ÙÙ…Ù„ÛŒ    â”‚ 120         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Sheet 4: Top Industries
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Industry       â”‚ Match Count â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ÙÙ„Ø²Ø§Øª Ø§Ø³Ø§Ø³ÛŒ    â”‚ 300         â”‚
â”‚ Ø®ÙˆØ¯Ø±Ùˆ          â”‚ 150         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ–¥ï¸ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² UI

### Ø¯Ø³ØªØ±Ø³ÛŒ
```
http://localhost:8000/analytics
```

### Ù…Ø±Ø§Ø­Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡

#### 1. Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø§Ù†Ø§Ù„
- Ø§Ø² Ù„ÛŒØ³Øª Ú©Ø´ÙˆÛŒÛŒ "Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø§Ù†Ø§Ù„" ÛŒÚ© Ú©Ø§Ù†Ø§Ù„ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯
- Ø³ÛŒØ³ØªÙ… Ø®ÙˆØ¯Ú©Ø§Ø± Ø¢Ù…Ø§Ø± Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯

#### 2. Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ
- 5 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø§Ø®ÛŒØ±: Ø¨Ø±Ø§ÛŒ monitoring Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ
- 30 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø§Ø®ÛŒØ±: Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø±ÛŒØ¹
- 1 Ø³Ø§Ø¹Øª Ø§Ø®ÛŒØ±: Ø¢Ù…Ø§Ø± Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª
- Ø§Ù…Ø±ÙˆØ²: Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø§Ù…Ø±ÙˆØ²
- 7 Ø±ÙˆØ² Ø§Ø®ÛŒØ±: Ø¨Ø±Ø±Ø³ÛŒ Ù‡ÙØªÚ¯ÛŒ
- 30 Ø±ÙˆØ² Ø§Ø®ÛŒØ±: ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù‡Ø§Ù†Ù‡

#### 3. Ø¨Ø±Ø±Ø³ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§

**Ú©Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ø¢Ù…Ø§Ø±** (Ø¨Ø§Ù„Ø§ÛŒ ØµÙØ­Ù‡):
- ØªØ¹Ø¯Ø§Ø¯ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§
- ØªØ¹Ø¯Ø§Ø¯ ØªØ·Ø§Ø¨Ù‚â€ŒÙ‡Ø§
- Ø¯Ø±ØµØ¯ ØªØ·Ø§Ø¨Ù‚
- ØªÙ…Ø±Ú©Ø² Ø§ØµÙ„ÛŒ

**Ù†Ù…ÙˆØ¯Ø§Ø± 10 Ù†Ù…Ø§Ø¯ Ø¨Ø±ØªØ±** (Bar Chart):
- Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨ÛŒØ´ØªØ±ÛŒÙ† ØªÚ©Ø±Ø§Ø± Ø±Ø§ Ø¯Ø§Ø±Ù†Ø¯
- Ù…Ù‚Ø§ÛŒØ³Ù‡ ØªØ¹Ø¯Ø§Ø¯ ØªÚ©Ø±Ø§Ø±

**Ù†Ù…ÙˆØ¯Ø§Ø± Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§** (Pie Chart):
- ØªÙˆØ²ÛŒØ¹ Ù…Ø­ØªÙˆØ§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§
- Ø¯Ø±Ú© ØªÙ…Ø±Ú©Ø² Ú©Ù„ÛŒ Ú©Ø§Ù†Ø§Ù„

**Ø¬Ø¯ÙˆÙ„ 10 ØµÙ†Ø¹Øª Ø¨Ø±ØªØ±**:
- Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ØµÙ†Ø§ÛŒØ¹
- Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨ØµØ±ÛŒ

#### 4. Ø®Ø±ÙˆØ¬ÛŒ Excel
- Ú©Ù„ÛŒÚ© Ø±ÙˆÛŒ Ø¯Ú©Ù…Ù‡ "Ø®Ø±ÙˆØ¬ÛŒ Excel"
- ÙØ§ÛŒÙ„ Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯
- Ù†Ø§Ù… ÙØ§ÛŒÙ„: `channel_analytics_{channel_id}_{date}.xlsx`

---

## ğŸ¨ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§

### Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Chart.js

```javascript
// Ù†Ù…ÙˆØ¯Ø§Ø± Ù…ÛŒÙ„Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§
new Chart(ctx, {
    type: 'bar',
    data: {
        labels: symbols.map(s => s.word),
        datasets: [{
            label: 'ØªØ¹Ø¯Ø§Ø¯',
            data: symbols.map(s => s.count),
            backgroundColor: 'rgba(59, 130, 246, 0.8)'
        }]
    },
    options: {
        responsive: true,
        maintainAspectRatio: false
    }
});

// Ù†Ù…ÙˆØ¯Ø§Ø± Ø¯Ø§ÛŒØ±Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§
new Chart(ctx, {
    type: 'pie',
    data: {
        labels: categories.map(c => c.name),
        datasets: [{
            data: categories.map(c => c.count),
            backgroundColor: colors
        }]
    },
    options: {
        plugins: {
            legend: {
                position: 'right',
                rtl: true
            }
        }
    }
});
```

---

## âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª

### ÙØ§ØµÙ„Ù‡ Ø²Ù…Ø§Ù†ÛŒ Aggregation

Ø¯Ø± `src/services/scheduler_service.py`:

```python
def add_analytics_aggregation_job(
    self,
    interval_minutes: int = 5,  # â† ÙØ§ØµÙ„Ù‡ Ø¨Ù‡ Ø¯Ù‚ÛŒÙ‚Ù‡
    job_id: str = "analytics_aggregation_job"
)
```

**ØªØºÛŒÛŒØ± ÙØ§ØµÙ„Ù‡**:
```python
# Ø¯Ø± main.py
scheduler_service.add_analytics_aggregation_job(interval_minutes=10)
```

### Ø³Ø·Ø­ Granularity

```python
# Hourly aggregates
await analytics_service.compute_aggregates(
    start_datetime=start,
    end_datetime=end,
    granularity="hourly"  # ÛŒØ§ "daily"
)
```

---

## ğŸ” Query Ù‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡

### Ù…Ø«Ø§Ù„ 1: Top Symbols

```python
async def _get_top_words_by_category(
    self,
    message_ids: List[uuid.UUID],
    category_name: str,
    limit: int = 10
):
    # Ú¯Ø±ÙØªÙ† category
    category = await session.execute(
        select(DictionaryCategory)
        .where(DictionaryCategory.name == category_name)
    )

    # Ø´Ù…Ø§Ø±Ø´ Ú©Ù„Ù…Ø§Øª
    result = await session.execute(
        select(
            DictionaryWord.id,
            DictionaryWord.word,
            func.count(MessageDictionary.id).label('count')
        )
        .join(MessageDictionary, MessageDictionary.word_id == DictionaryWord.id)
        .where(
            and_(
                MessageDictionary.message_id.in_(message_ids),
                DictionaryWord.category_id == category.id
            )
        )
        .group_by(DictionaryWord.id, DictionaryWord.word)
        .order_by(func.count(MessageDictionary.id).desc())
        .limit(limit)
    )

    return [
        {"id": str(row.id), "word": row.word, "count": row.count}
        for row in result
    ]
```

### Ù…Ø«Ø§Ù„ 2: Top Industries

```python
async def _get_top_industries(
    self,
    message_ids: List[uuid.UUID],
    limit: int = 10
):
    # Ú¯Ø±ÙØªÙ† ØªÙ…Ø§Ù… words Ø¨Ø§ extra_data
    result = await session.execute(
        select(
            DictionaryWord.extra_data,
            func.count(MessageDictionary.id).label('count')
        )
        .join(MessageDictionary)
        .where(
            and_(
                MessageDictionary.message_id.in_(message_ids),
                DictionaryWord.extra_data.isnot(None)
            )
        )
        .group_by(DictionaryWord.extra_data)
    )

    # Ø´Ù…Ø§Ø±Ø´ ØµÙ†Ø§ÛŒØ¹
    industry_counter = Counter()
    for row in result:
        extra_data = row.extra_data or {}
        industry_name = extra_data.get('industry_name')
        if industry_name:
            industry_counter[industry_name] += row.count

    # Top 10
    return [
        {"name": name, "count": count}
        for name, count in industry_counter.most_common(limit)
    ]
```

---

## ğŸ“ˆ Performance

### Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒâ€ŒÙ‡Ø§

1. **Indexes**:
```sql
CREATE INDEX idx_channel_analytics_channel_date
ON channel_analytics(channel_id, date);

CREATE INDEX idx_channel_analytics_date
ON channel_analytics(date);
```

2. **JSONB Indexing** (Ø¢ÛŒÙ†Ø¯Ù‡):
```sql
CREATE INDEX idx_top_symbols
ON channel_analytics USING gin(top_symbols);
```

3. **Caching**:
```python
# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Redis Ø¨Ø±Ø§ÛŒ cache Ú©Ø±Ø¯Ù† Ù†ØªØ§ÛŒØ¬
cache_key = f"analytics:{channel_id}:{time_range}"
cached = await redis.get(cache_key)
if cached:
    return cached

# Ù…Ø­Ø§Ø³Ø¨Ù‡...
await redis.setex(cache_key, 300, result)  # 5 min TTL
```

---

## ğŸ› Debugging

### Ú†Ú© Ú©Ø±Ø¯Ù† Aggregates

```sql
-- Ø¢Ø®Ø±ÛŒÙ† aggregates
SELECT * FROM channel_analytics
ORDER BY created_at DESC
LIMIT 10;

-- aggregates ÛŒÚ© Ú©Ø§Ù†Ø§Ù„ Ø®Ø§Øµ
SELECT
  date,
  hour,
  message_count,
  match_count,
  top_symbols
FROM channel_analytics
WHERE channel_id = 'uuid-here'
ORDER BY date DESC, hour DESC
LIMIT 24;  -- 24 Ø³Ø§Ø¹Øª Ø§Ø®ÛŒØ±
```

### Ú†Ú© Ú©Ø±Ø¯Ù† Job

```python
# Ø¯Ø± Python shell
from src.database import db_manager
from src.core.analytics.channel_analytics_service import ChannelAnalyticsService

db_manager.init_engine()

async with db_manager.session() as session:
    service = ChannelAnalyticsService(session)

    # Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø³ØªÛŒ
    from datetime import datetime, timedelta
    now = datetime.utcnow()
    start = now - timedelta(hours=1)

    count = await service.compute_aggregates(
        start_datetime=start,
        end_datetime=now,
        granularity="hourly"
    )

    print(f"Created {count} records")
```

---

## ğŸ’¡ Ù†Ú©Ø§Øª Ùˆ ØªØ±ÙÙ†Ø¯Ù‡Ø§

### 1. ØªÙØ³ÛŒØ± Ø¯Ø±ØµØ¯ ØªØ·Ø§Ø¨Ù‚

```
< 10%: Ú©Ø§Ù†Ø§Ù„ Ø¹Ù…ÙˆÙ…ÛŒØŒ Ù…Ø­ØªÙˆØ§ÛŒ Ù…ØªÙ†ÙˆØ¹
10-30%: Ú©Ø§Ù†Ø§Ù„ Ù†ÛŒÙ…Ù‡â€ŒØªØ®ØµØµÛŒ
30-60%: Ú©Ø§Ù†Ø§Ù„ ØªØ®ØµØµÛŒ
> 60%: Ú©Ø§Ù†Ø§Ù„ Ø¨Ø³ÛŒØ§Ø± ØªØ®ØµØµÛŒ
```

### 2. Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Trending Topics

```python
# Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø§Ù…Ø±ÙˆØ² Ø¨Ø§ Ø¯ÛŒØ±ÙˆØ²
today_stats = get_stats(today)
yesterday_stats = get_stats(yesterday)

for symbol in today_stats.top_symbols:
    yesterday_count = get_count(yesterday_stats, symbol.word)
    growth = (symbol.count - yesterday_count) / yesterday_count * 100
    if growth > 50:
        print(f"{symbol.word} is trending! (+{growth}%)")
```

### 3. Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡

```python
# Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ primary_focus Ù…Ø´Ø§Ø¨Ù‡
similar_channels = await session.execute(
    select(ChannelAnalytics)
    .where(
        ChannelAnalytics.top_categories.contains([
            {"name": "Ù†Ù…Ø§Ø¯Ù‡Ø§"}
        ])
    )
    .distinct(ChannelAnalytics.channel_id)
)
```

---

## ğŸ¯ Ù…ÙˆØ§Ø±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ ÙˆØ§Ù‚Ø¹ÛŒ

### Ù…Ø«Ø§Ù„ 1: Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¨Ù‡ØªØ±ÛŒÙ† Ú©Ø§Ù†Ø§Ù„ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù†Ù…Ø§Ø¯

```python
# Ú©Ø¯Ø§Ù… Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ Ø¨ÛŒØ´ØªØ± Ø¯Ø±Ø¨Ø§Ø±Ù‡ "ÙÙˆÙ„Ø§Ø¯" ØµØ­Ø¨Øª Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ØŸ

# 1. Ú¯Ø±ÙØªÙ† ØªÙ…Ø§Ù… aggregates 7 Ø±ÙˆØ² Ø§Ø®ÛŒØ±
analytics = await session.execute(
    select(ChannelAnalytics)
    .where(ChannelAnalytics.date >= last_week)
)

# 2. ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† aggregates Ú©Ù‡ ÙÙˆÙ„Ø§Ø¯ Ø¯Ø± top symbols Ø¯Ø§Ø±Ù†Ø¯
channels_with_foolad = []
for record in analytics:
    symbols = record.top_symbols or []
    for symbol in symbols:
        if symbol['word'] == 'ÙÙˆÙ„Ø§Ø¯':
            channels_with_foolad.append({
                'channel_id': record.channel_id,
                'count': symbol['count']
            })

# 3. Sort Ú©Ø±Ø¯Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ count
channels_with_foolad.sort(key=lambda x: x['count'], reverse=True)
```

### Ù…Ø«Ø§Ù„ 2: ØªØ­Ù„ÛŒÙ„ Ø§Ù„Ú¯ÙˆÛŒ Ø²Ù…Ø§Ù†ÛŒ Ú©Ø§Ù†Ø§Ù„

```python
# Ú©Ø§Ù†Ø§Ù„ Ø¯Ø± Ú†Ù‡ Ø³Ø§Ø¹Ø§ØªÛŒ ÙØ¹Ø§Ù„â€ŒØªØ± Ø§Ø³ØªØŸ

hourly_stats = await session.execute(
    select(
        ChannelAnalytics.hour,
        func.avg(ChannelAnalytics.message_count).label('avg_count')
    )
    .where(
        and_(
            ChannelAnalytics.channel_id == channel_id,
            ChannelAnalytics.hour.isnot(None),
            ChannelAnalytics.date >= last_month
        )
    )
    .group_by(ChannelAnalytics.hour)
    .order_by(ChannelAnalytics.hour)
)

# Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø±
for hour, avg_count in hourly_stats:
    bar = 'â–ˆ' * int(avg_count / 10)
    print(f"{hour:02d}:00 {bar} {avg_count:.1f}")
```

---

**Ø¢Ø®Ø±ÛŒÙ† Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ**: 2025-11-16
**Ù†Ø³Ø®Ù‡**: 1.0
